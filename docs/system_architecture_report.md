# รายงานรายละเอียดโครงสร้างระบบ Etymology AI

รายงานฉบับนี้อธิบายถึงสถาปัตยกรรมของระบบ Etymology AI ซึ่งเป็นระบบปัญญาประดิษฐ์สำหรับการวิเคราะห์รากศัพท์ (Etymology) และการตรวจจับคําที่มีรากศัพท์เดียวกัน (Cognate Detection) ข้ามภาษา โดยเน้นที่ภาษาไทยและภาษาตระกูลอินโด-ยูโรเปียน (เช่น สันสกฤต, บาลี)

## 1. บทสรุปผู้บริหาร (System Overview)

ระบบ Etymology AI ถูกออกแบบมาเพื่อแก้ปัญหาการสืบค้นที่มาของคำโดยใช้เทคนิค Deep Learning ผสมผสานกับหลักภาษาศาสตร์ (Phonetics & Linguistics) ระบบทำงานโดยการเปลี่ยนคำศัพท์ให้เป็นรูปสัทอักษรสากล (IPA) แล้วแปลงเป็นเวกเตอร์ทางคณิตศาสตร์ (Embeddings) เพื่อเปรียบเทียบความคล้ายคลึงของเสียงและโครงสร้างคำ โมเดลสามารถเรียนรู้ความสัมพันธ์ของคำศัพท์ผ่านกราฟรากศัพท์ (Etymology Graph) เพื่อทำนายความเชื่อมโยงที่อาจตกหล่นไปในฐานข้อมูลเดิม

---

## 2. สถาปัตยกรรมข้อมูล (Data Pipeline)

กระบวนการจัดการข้อมูลแบ่งออกเป็น 3 ขั้นตอนหลัก: การรวบรวม (Ingestion), การประมวลผล (Processing), และการจัดเก็บ (Storage)

### 2.1 แหล่งข้อมูล (Data Sources)
ระบบรองรับการดึงข้อมูลจากแหล่งข้อมูลทางภาษาศาสตร์หลัก 4 แหล่ง ผ่าน `src/data/downloaders.py`:
1.  **Kaikki (Wiktionary)**: ฐานข้อมูลหลักสำหรับข้อมูล Etymology แยกตามภาษา (เช่น Thai, Sanskrit) ซึ่งให้ข้อมูลในรูปแบบ JSONL
2.  **WOLD (World Loanword Database)**: ฐานข้อมูลคำยืม โดยเน้นคำยืมในภาษาไทย
3.  **Starling**: ฐานข้อมูลรากศัพท์ Proto-Indo-European (PIE)
4.  **PanLex**: แหล่งข้อมูลสำหรับการแปลความหมายข้ามภาษา

### 2.2 การประมวลผลทางภาษา (Linguistic Processing)
หัวใจสำคัญของการประมวลผลคือ `src/data/phonetic_converter.py` ซึ่งทำหน้าที่:
*   **IPA Conversion**: แปลงคำศัพท์จากอักขรวิธีภาษานั้นๆ ให้เป็นสัทอักษรสากล (IPA)
    *   **ไทย (Thai)**: ใช้ PyThaiNLP ในการถอดเสียงแล้วแปลงเป็น IPA (เช่น มารดา -> m aː n d aː)
    *   **สันสกฤต/บาลี (Sanskrit/Pali)**: ใช้กฎการแปลงแบบ Rule-based จากระบบ IAST เป็น IPA (เช่น mātṛ -> m aː t r̩)
    *   **ภาษาอื่นๆ**: ใช้ไลบรารี `Epitran` หรือ `Panphon` สำหรับภาษามาตรฐานสากล
*   **Feature Extraction**: ถอดรหัส Phoneme ใน IPA ให้เป็นชุดคุณลักษณะ (Phonetic Features) เช่น เสียงก้อง (Voiced), ฐานกรณ์ (Place of articulation) เพื่อใช้ในการคำนวณระยะห่างทางเสียง (Weighted Feature Edit Distance)

---

## 3. สถาปัตยกรรมโมเดล (Model Architecture)

ระบบประกอบด้วยโมเดล 3 ส่วนหลักที่ทำงานประสานกัน อยู่ใน `src/models/`:

### 3.1 Phonetic Embedding Model (Transformer)
*   **ไฟล์**: `src/models/phonetic_embedding.py`
*   **หน้าที่**: แปลงสายอักขระ IPA ให้เป็นเวกเตอร์ความหนาแน่นสูง (Dense Vector) ขนาด 512 มิติ
*   **สถาปัตยกรรม**:
    *   **Input**: ลำดับของอักขระ IPA
    *   **Embedding Layer**: แปลงอักขระเป็นเวกเตอร์เบื้องต้น
    *   **Positional Encoding**: ระบุตำแหน่งของเสียงในคำ
    *   **Transformer Encoder**: ใช้สถาปัตยกรรม Self-Attention จำนวน 6 เลเยอร์ เพื่อจับบริบทความสัมพันธ์ของเสียงหน้า-หลัง
    *   **Pooling**: รวบรวมข้อมูลทั้งลำดับให้เหลือเวกเตอร์เดียว (Mean/Max/CLS Pooling)
*   **การเทรน**: ใช้เทคนิค **Masked Language Modeling (MLM)** คือการปิดบางเสียงในคำ แล้วให้โมเดลทายเสียงที่หายไป เพื่อให้โมเดลเข้าใจโครงสร้างทางเสียงอย่างลึกซึ้ง

### 3.2 Siamese Network (Cognate Detection)
*   **ไฟล์**: `src/models/siamese_network.py`
*   **หน้าที่**: ตรวจจับว่าคำ 2 คำเป็น Cognate (รากศัพท์เดียวกัน) หรือไม่
*   **สถาปัตยกรรม**:
    *   ใช้ **Phonetic Embedding Model** 2 ตัว (แชร์น้ำหนักกัน) เพื่อแปลงคำทั้งสองเป็นเวกเตอร์
    *   นำเวกเตอร์มาคำนวณความคล้ายคลึง (Cosine Similarity หรือ Euclidean Distance)
*   **การเทรน**: ใช้ **Triplet Loss** หรือ **Contrastive Loss** โดยป้อนข้อมูลเป็นคู่ (คำเหมือน/คำต่าง) หรือสามตัว (คำตั้งต้น, คำเหมือน, คำต่าง) เพื่อบีบให้เวกเตอร์ของคำที่มีรากศัพท์เดียวกันอยู่ใกล้กันในปริภูมิเวกเตอร์

### 3.3 Etymology Graph Neural Network (GAT)
*   **ไฟล์**: `src/models/etymology_gnn.py`
*   **หน้าที่**: วิเคราะห์โครงสร้างความสัมพันธ์ในรูปแบบกราฟ เพื่อทำนายความเชื่อมโยงที่ซับซ้อน (Link Prediction)
*   **สถาปัตยกรรม**:
    *   **Graph Attention Network (GAT)**: โมเดลเรียนรู้จากกราฟที่มี Node เป็นคำศัพท์ และ Edge เป็นความสัมพันธ์
    *   **Node Features**: ใช้ Phonetic Embedding รวมกับข้อมูลตระกูลภาษา (Language Family API)
    *   **Output**: ความน่าจะเป็นของการเชื่อมโยงระหว่างคำ (Link Probability)

---

## 4. กระบวนการทำงานของระบบ (System Workflow)

1.  **Data Ingestion**: ระบบดึงข้อมูลดิบจาก Wiktionary และแหล่งอื่นๆ
2.  **Preprocessing**: ข้อมูลถูกกรองและแปลงเป็นคู่คำศัพท์ (Source-Target) พร้อมแปลงเป็น IPA
3.  **Encoding**: คำศัพท์ IPA ถูกส่งผ่าน Phonetic Embedding Model เพื่อสร้างเวกเตอร์แทนเสียง
4.  **Similarity & Graph Analysis**:
    *   สำหรับคู่คำ: ใช้ Siamese Network คำนวณคะแนนความคล้ายคลึง
    *   สำหรับโครงสร้างใหญ่: ใช้ GNN วิเคราะห์กราฟความสัมพันธ์หา Link ที่ขาดหายไป
5.  **Prediction**: ระบบแสดงผลลัพธ์เป็นคะแนนความมั่นใจ (Confidence Score) ว่าคำคู่นั้นมีรากศัพท์เดียวกันหรือไม่

---

## สรุป
ระบบนี้เป็นการประยุกต์ใช้ NLP สมัยใหม่ (Transformers) ร่วมกับความรู้ทางนิรุกติศาสตร์ (Historical Linguistics) ได้อย่างลงตัว โดยมีจุดเด่นขีดความสามารถในการทำความเข้าใจ "เสียง" ของคำมากกว่าแค่ตัวอักษร ทำให้สามารถตรวจจับคำที่มีรากศัพท์เดียวกันข้ามภาษาที่มีระบบการเขียนต่างกันได้ (เช่น ไทย-อังกฤษ หรือ ไทย-บาลี)
